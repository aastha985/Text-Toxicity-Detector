# Text-Toxicity-Detector
Using text toxicity detection model from Tensorflow.js.

[Live Demo](https://aastha985.github.io/Text-Toxicity-Detector/)

Detects whether the entered text contains toxic content:
* identity attack
* insult
* obscene
* severe toxicity
* sexual explicit
* threat
* toxicity


